{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: [0 1 2 3 4 5 6]\n",
      "Total Datapoints: 1272462\n",
      "Counts Per Class:\n",
      "0     23109\n",
      "1     28784\n",
      "2     37183\n",
      "3     48595\n",
      "4    173049\n",
      "5    443753\n",
      "6    517989\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>explicit</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.782</td>\n",
       "      <td>0.633</td>\n",
       "      <td>106471</td>\n",
       "      <td>0.2610</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.235</td>\n",
       "      <td>-16.389</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7970</td>\n",
       "      <td>167.679</td>\n",
       "      <td>0.655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.988</td>\n",
       "      <td>0.420</td>\n",
       "      <td>232933</td>\n",
       "      <td>0.0909</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7860</td>\n",
       "      <td>10</td>\n",
       "      <td>0.104</td>\n",
       "      <td>-19.388</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0409</td>\n",
       "      <td>123.089</td>\n",
       "      <td>0.227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.993</td>\n",
       "      <td>0.394</td>\n",
       "      <td>177981</td>\n",
       "      <td>0.2580</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0770</td>\n",
       "      <td>5</td>\n",
       "      <td>0.153</td>\n",
       "      <td>-9.779</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1100</td>\n",
       "      <td>74.761</td>\n",
       "      <td>0.340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.730</td>\n",
       "      <td>0.618</td>\n",
       "      <td>125300</td>\n",
       "      <td>0.2720</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.146</td>\n",
       "      <td>-18.515</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7310</td>\n",
       "      <td>67.141</td>\n",
       "      <td>0.449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.993</td>\n",
       "      <td>0.475</td>\n",
       "      <td>188600</td>\n",
       "      <td>0.4070</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0134</td>\n",
       "      <td>9</td>\n",
       "      <td>0.116</td>\n",
       "      <td>-13.011</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0492</td>\n",
       "      <td>74.130</td>\n",
       "      <td>0.594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   acousticness  danceability  duration_ms  energy  explicit  \\\n",
       "0         0.782         0.633       106471  0.2610         1   \n",
       "0         0.988         0.420       232933  0.0909         0   \n",
       "0         0.993         0.394       177981  0.2580         0   \n",
       "0         0.730         0.618       125300  0.2720         1   \n",
       "0         0.993         0.475       188600  0.4070         0   \n",
       "\n",
       "   instrumentalness  key  liveness  loudness  mode  speechiness    tempo  \\\n",
       "0            0.0000    1     0.235   -16.389     1       0.7970  167.679   \n",
       "0            0.7860   10     0.104   -19.388     1       0.0409  123.089   \n",
       "0            0.0770    5     0.153    -9.779     0       0.1100   74.761   \n",
       "0            0.0000    6     0.146   -18.515     1       0.7310   67.141   \n",
       "0            0.0134    9     0.116   -13.011     1       0.0492   74.130   \n",
       "\n",
       "   valence  \n",
       "0    0.655  \n",
       "0    0.227  \n",
       "0    0.340  \n",
       "0    0.449  \n",
       "0    0.594  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from scipy.stats import multivariate_normal # MVN not univariate\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import time\n",
    "\n",
    "np.random.seed(7)\n",
    "\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "file_path = \"data.csv\"\n",
    "df = pd.read_csv(file_path, index_col='year')\n",
    "\n",
    "file_path = \"tracks_features.csv\"\n",
    "df2 = pd.read_csv(file_path, index_col='year')\n",
    "\n",
    "df.drop(['artists','id', 'name', 'release_date','popularity' ], axis = 1, inplace = True)\n",
    "df2.drop(['artists','id', 'name', 'release_date', 'album_id','artist_ids', 'time_signature',\\\n",
    "          'track_number', 'disc_number', 'album' ], axis = 1, inplace = True)\n",
    "\n",
    "df = pd.concat([df,df2])\n",
    "\n",
    "\n",
    "### Only look at decades from 50s to 10s (2020 not included)\n",
    "l_drop = np.arange(1921,1950)\n",
    "l_drop = np.append(l_drop,2020)\n",
    "drop_vals = np.array([0,1900,1908,1909,1917,1920])\n",
    "l_drop = np.concatenate((l_drop,drop_vals))\n",
    "\n",
    "\n",
    "df.drop(labels=l_drop, axis=0, inplace = True)\n",
    "\n",
    "enc = LabelEncoder()\n",
    "labels = df.index\n",
    "standardized_labels = np.array(labels)\n",
    "enc.fit(df.index.unique())\n",
    "\n",
    "\n",
    "\n",
    "lmao = df.index\n",
    "y = enc.transform(standardized_labels)\n",
    "Y = enc.transform(np.unique(standardized_labels))\n",
    "\n",
    "y_decade = y//10\n",
    "Y_decade = np.unique(y_decade)\n",
    "\n",
    "enc.fit(df['explicit'].unique())\n",
    "df['explicit'] = enc.transform(df['explicit'])\n",
    "\n",
    "\n",
    "df.set_index(y_decade, inplace=True)\n",
    "\n",
    "aa = df.index.value_counts().sort_index().to_numpy()\n",
    "priors = aa/len(df.index)\n",
    "check = np.sum(priors)\n",
    "class_priors = np.diag(priors)\n",
    "num_classes = len(Y_decade)\n",
    "# print(df)\n",
    "\n",
    "\n",
    "N = len(df)\n",
    "print('Labels:',Y_decade)\n",
    "print('Total Datapoints:',N)\n",
    "print(\"Counts Per Class:\")\n",
    "print(df.index.value_counts().sort_index())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regularized_cov(X, lambda_reg):\n",
    "    n = X.shape[0]\n",
    "    sigma = np.cov(X)\n",
    "    # Selecting the regularization parameter should be performed using CV and a separate data subset\n",
    "    # As I only went by training set performance (overfitting) in this problem, I settled on lambda=1/n\n",
    "    sigma += lambda_reg * np.eye(n)\n",
    "    return sigma\n",
    "\n",
    "covariance = df.std()\n",
    "mean = df.mean()\n",
    "X = (df-df.mean())/df.std()\n",
    "# print(X)\n",
    "mu = X.groupby([X.index]).mean().to_numpy()\n",
    "n = mu.shape[1]\n",
    "Sigma = np.array([regularized_cov(X[y_decade == l].T,(1/n)) for l in range(num_classes)])\n",
    "# Sigma = np.array([np.cov(X[y_decade == l].T) for l in range(num_classes)])\n",
    "# print(mu)\n",
    "# print(Sigma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Samples: 1272462.0\n",
      "Confusion matrix:\n",
      "[[  1194    453    396    457   2708   7183   5409]\n",
      " [  2227   3087   1298    734   3319   8127   5721]\n",
      " [   927   2914   7341   7837  13729  23068  20787]\n",
      " [    14     22    254    828    571    579    470]\n",
      " [   977   1029    851   2481  17242  22931  22067]\n",
      " [ 16305  19566  24178  30310 106524 284366 286614]\n",
      " [  1465   1713   2865   5948  28956  97499 176921]]\n",
      "Total Mumber of Misclassified Samples: 781483.0\n",
      "Empirically Estimated Probability of Error: 0.6142\n",
      "Accuracy: 0.38584963637421\n"
     ]
    }
   ],
   "source": [
    "C = len(priors)\n",
    "class_cond_likelihoods = np.array([multivariate_normal.pdf(X, mu[j], Sigma[j]) for j in range(C)])\n",
    "# print(np.max(class_cond_likelihoods))\n",
    "\n",
    "# Class Posterior\n",
    "# P(yj | x) = p(x | yj) * P(yj) / p(x)\n",
    "class_posteriors = class_priors.dot(class_cond_likelihoods)\n",
    "\n",
    "decisions = np.argmax(class_posteriors, axis=0)\n",
    "\n",
    "sample_class_counts = np.array([sum(y == j) for j in Y_decade])\n",
    "\n",
    "\n",
    "conf_mat = np.zeros((C, C))\n",
    "display_mat = np.zeros((C,C))\n",
    "for i in range(C): # Each decision option\n",
    "    for j in range(C): # Each class label\n",
    "        ind_ij = np.argwhere((decisions==Y_decade[i]) & (y_decade==Y_decade[j]))\n",
    "        display_mat[i, j] = len(ind_ij) # Average over class sample count\n",
    "        conf_mat[i, j] = len(ind_ij)/sample_class_counts[j]\n",
    "\n",
    "print(\"Total Number of Samples:\",np.sum(display_mat))\n",
    "print(\"Confusion matrix:\")\n",
    "print(display_mat.astype(int))\n",
    "# print(1950+(Y_decade*10))\n",
    "\n",
    "correct_class_samples = np.sum(np.diag(display_mat))\n",
    "print(\"Total Mumber of Misclassified Samples: {}\".format(N - correct_class_samples))\n",
    "\n",
    "prob_error = 1 - (correct_class_samples / N)\n",
    "print(\"Empirically Estimated Probability of Error: {:.4f}\".format(prob_error))\n",
    "print(\"Accuracy:\",1-prob_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "done\n",
      "loudness            0.106529\n",
      "duration_ms         0.097045\n",
      "valence             0.096244\n",
      "energy              0.092916\n",
      "acousticness        0.092595\n",
      "tempo               0.092480\n",
      "danceability        0.091840\n",
      "speechiness         0.090485\n",
      "liveness            0.089905\n",
      "instrumentalness    0.080881\n",
      "key                 0.054196\n",
      "mode                0.009507\n",
      "explicit            0.005376\n",
      "dtype: float64\n",
      "\n",
      "ACCURACY OF THE MODEL:  0.47502351082807887\n",
      "\n",
      "Time to run (sec):  353.89380073547363\n",
      "Time to run (min):  5.898230012257894\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.values, y_decade, test_size = 0.30)\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators = 100)\n",
    "print('done')\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print('done')\n",
    "\n",
    "feature_imp = pd.Series(clf.feature_importances_, index = df.columns).sort_values(ascending = False)\n",
    "print('done')\n",
    "\n",
    "print(feature_imp)\n",
    "\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    " \n",
    "# metrics are used to find accuracy or error\n",
    "from sklearn import metrics \n",
    "print()\n",
    " \n",
    "# using metrics module for accuracy calculation\n",
    "print(\"ACCURACY OF THE MODEL: \", metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "stop = time.time()\n",
    "print()\n",
    "print('Time to run (sec): ', stop - start) \n",
    "print('Time to run (min): ', (stop - start)/60) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.cuda.device at 0x22e77fede20>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# Utility to visualize PyTorch network and shapes\n",
    "from torchsummary import summary\n",
    "from sklearn.model_selection import KFold # Important new include\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "torch.manual_seed(7)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "torch.cuda.device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLayerMLP(nn.Module):\n",
    "    # Two-layer MLP (not really a perceptron activation function...) network class\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, C):\n",
    "        super(TwoLayerMLP, self).__init__()\n",
    "        # Fully connected layer WX + b mapping from input_dim (n) -> hidden_layer_dim\n",
    "        self.input_fc = nn.Linear(input_dim, hidden_dim)\n",
    "        # Output layer again fully connected mapping from hidden_layer_dim -> outputs_dim (C)\n",
    "        self.output_fc = nn.Linear(hidden_dim, C)\n",
    "        # Log Softmax (faster and better than straight Softmax)\n",
    "        # dim=1 refers to the dimension along which the softmax operation is computed\n",
    "        # In this case computing probabilities across dim 1, i.e., along classes at output layer\n",
    "        self.log_softmax = nn.LogSoftmax(dim=1) \n",
    "        \n",
    "    # Don't call this function directly!! \n",
    "    # Simply pass input to model and forward(input) returns output, e.g. model(X)\n",
    "    def forward(self, X):\n",
    "        # X = [batch_size, input_dim (n)]\n",
    "        X = self.input_fc(X)\n",
    "        # Non-linear activation function, e.g. ReLU (default good choice)\n",
    "        # Could also choose F.softplus(x) for smooth-ReLU, empirically worse than ReLU\n",
    "        X = F.relu(X)\n",
    "        # X = [batch_size, hidden_dim]\n",
    "        # Connect to last layer and output 'logits'\n",
    "        X = self.output_fc(X)\n",
    "        # Squash logits to probabilities that sum up to 1\n",
    "        y = self.log_softmax(X)\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train(model, data, labels, criterion, optimizer, num_epochs=25):\n",
    "\n",
    "    # Apparently good practice to set this \"flag\" too before training\n",
    "    # Does things like make sure Dropout layers are active, gradients are updated, etc.\n",
    "    # Probably not a big deal for our toy network, but still worth developing good practice\n",
    "#     model.to(device)\n",
    "#     data = data.to(device)\n",
    "#     print(data.device)\n",
    "    \n",
    "    model.train()\n",
    "    # Optimize the neural network\n",
    "    for epoch in range(num_epochs):\n",
    "        # These outputs represent the model's predicted probabilities for each class. \n",
    "        outputs = model(data)\n",
    "        # Criterion computes the cross entropy loss between input and target\n",
    "        loss = criterion(outputs, labels)\n",
    "        # Set gradient buffers to zero explicitly before backprop\n",
    "        optimizer.zero_grad()\n",
    "        # Backward pass to compute the gradients through the network\n",
    "        loss.backward()\n",
    "        # GD step update\n",
    "        optimizer.step()\n",
    "        \n",
    "    return model\n",
    "    \n",
    "    \n",
    "def model_predict(model, data, labels):\n",
    "    # Similar idea to model.train(), set a flag to let network know your in \"inference\" mode\n",
    "#     model.to(device)\n",
    "    labels.to(device)\n",
    "\n",
    "    model.eval()\n",
    "    N = len(data)\n",
    "#     print(N)\n",
    "    # Disabling gradient calculation is useful for inference, only forward pass!!\n",
    "    with torch.no_grad():\n",
    "        # Evaluate nn on test data and compare to true labels\n",
    "        predicted_labels = model(data)\n",
    "        # Back to numpy\n",
    "        predicted_labels = predicted_labels.detach().cpu().numpy()\n",
    "        Z = np.argmax(predicted_labels, 1)\n",
    "#     print(labels)\n",
    "    conf_mat = confusion_matrix(Z, labels.cpu())\n",
    "    correct_class_samples = np.sum(np.diag(conf_mat))\n",
    "    prob_error = 1 - (correct_class_samples / N)\n",
    "#     print(conf_mat)\n",
    "#     print(\"Total Number of Misclassified Samples: {:d}\".format(N - correct_class_samples))\n",
    "#     print(\"Empirically Estimated Probability of Error: {:.4f}\".format(prob_error))\n",
    "#     print()\n",
    "    return Z, prob_error\n",
    "\n",
    "# Z, acc = model_predict(model,X_tensor[0],labels[0])\n",
    "# print(acc)\n",
    "\n",
    "def neuron_cross_validation(X,labels,X_tensor,l_tensor):#,Xtest,labelsTest):\n",
    "\n",
    "    K = 10\n",
    "    kf = KFold(n_splits=K, shuffle=True)\n",
    "    start = 1\n",
    "    trials = 100\n",
    "    neurons = np.arange(start, start+trials, 1)\n",
    "    n_hidden = len(neurons)\n",
    "    \n",
    "#     X = X.to(device)\n",
    "#     labels = labels.to(device)\n",
    "    X_tensor = X_tensor.to(device)\n",
    "    l_tensor = l_tensor.to(device)\n",
    "    \n",
    "    # Store predictions per degree using ordered X samples for plotting best fit lines\n",
    "#     y_train_preds_ordered = np.empty(n_degs, dtype=np.ndarray)\n",
    "    # Allocate space for CV\n",
    "    # No need for training loss storage too but useful comparison\n",
    "    mse_valid_mk = np.empty((n_hidden, K)) \n",
    "    mse_train_mk = np.empty((n_hidden, K)) # Indexed by model m, data partition k\n",
    "    acc = np.empty((n_hidden, K))\n",
    "    accTest = np.empty(n_hidden)\n",
    "    i = 0\n",
    "    for n in neurons: \n",
    "        start_it = time.time()\n",
    "        k = 0\n",
    "        for train_indices, valid_indices in kf.split(X):\n",
    "            # Extract the training and validation sets from the K-fold split\n",
    "            X_train_k = X_tensor[train_indices]\n",
    "            y_train_k = l_tensor[train_indices]\n",
    "            X_train_tensor = (X_train_k)\n",
    "            y_train_tensor = (y_train_k)\n",
    "            \n",
    "            X_valid_k = X_tensor[valid_indices]\n",
    "            y_valid_k = l_tensor[valid_indices]\n",
    "            X_valid_tensor = (X_valid_k)\n",
    "\n",
    "            #Assign data to GPU\n",
    "#             X_train_k.to(device)\n",
    "#             y_train_k = labels[train_indices]\n",
    "#             X_train_tensor = torch.FloatTensor(X_train_k)\n",
    "#             y_train_tensor = torch.LongTensor(y_train_k)\n",
    "            \n",
    "#             X_valid_k = X[valid_indices]\n",
    "#             y_valid_k = labels[valid_indices]\n",
    "#             X_valid_tensor = torch.FloatTensor(X_valid_k)\n",
    "            \n",
    "            #Train it\n",
    "            model = TwoLayerMLP(input_dim, n, output_dim)\n",
    "            model.to(device)\n",
    "            optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            num_epochs = 100\n",
    "            model = model_train(model, X_train_tensor, y_train_tensor, criterion, optimizer, num_epochs=num_epochs)\n",
    "            \n",
    "            #Validate/predict it and record p(error)\n",
    "            Z, acc[i,k] = model_predict(model,X_valid_tensor,y_valid_k)\n",
    "#             Z, accTest[i,k] = model_predict(model,X_tensor_test,labelsTest)\n",
    "            k += 1\n",
    "        i+=1\n",
    "#         print(i, 'done')\n",
    "\n",
    "        stop_it = time.time()\n",
    "        t = stop_it - start_it\n",
    "#         print('Time to run {}th iteration: {}'.format(i,t)) \n",
    "        print('Time to run {}th iteration:'.format(i))\n",
    "        print('{} minutes'.format(t/60)) \n",
    "        print()\n",
    "    accuracy = np.mean(acc, axis=1)\n",
    "    min_acc = np.min(accuracy)\n",
    "    min_ind = np.argmin(accuracy)\n",
    "    n_optimal = neurons[min_ind]\n",
    "    \n",
    "    return min_ind, min_acc, n_optimal, accuracy, acc#, models, accTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "done\n",
      "890723\n",
      "381739\n"
     ]
    }
   ],
   "source": [
    "# device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "torch.cuda.device(device)\n",
    "\n",
    "# return\n",
    "input_dim = X.shape[1]\n",
    "n_hidden_neurons = 16   #VARY THIS FOR CV\n",
    "output_dim = C\n",
    "\n",
    "# It's called an MLP but really it's not...\n",
    "# model = TwoLayerMLP(input_dim, n_hidden_neurons, output_dim)\n",
    "# model.to(device)\n",
    "# # Visualize network architecture\n",
    "# print(model)\n",
    "# summary(model, input_size=(16, input_dim))\n",
    "\n",
    "# X_train, X_test, y_train, y_test\n",
    "\n",
    "# X_arr = X.to_numpy()\n",
    "\n",
    "# X_tensor = torch.FloatTensor(X_arr)\n",
    "# l_tensor = torch.LongTensor(y_decade)\n",
    "\n",
    "\n",
    "# X_arr_train = X_train.to_numpy()\n",
    "# X_arr_test = X_test.to_numpy()\n",
    "\n",
    "X_tensor_train = torch.FloatTensor(X_train)\n",
    "X_tensor_test = torch.FloatTensor(X_test)\n",
    "\n",
    "\n",
    "l_tensor_train = torch.LongTensor(y_train)\n",
    "l_tensor_test = torch.LongTensor(y_test)\n",
    "\n",
    "\n",
    "# X_tensor_train = torch.FloatTensor(X_train)\n",
    "# X_tensor_test = torch.FloatTensor(X_test)\n",
    "\n",
    "\n",
    "# l_tensor_train = torch.LongTensor(y_train)\n",
    "# l_tensor_test = torch.LongTensor(y_test)\n",
    "#     X.to(device)\n",
    "#     labels.to(device)\n",
    "#     X_tensor.to(device)\n",
    "#     l_tensor.to(device)\n",
    "\n",
    "print('done')\n",
    "# Convert numpy structures to PyTorch tensors, as these are the data types required by the library\n",
    "print(len(X_train))\n",
    "print(len(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to run 1th iteration:\n",
      "0.49944976170857747 minutes\n",
      "\n",
      "Time to run 2th iteration:\n",
      "0.4428159554799398 minutes\n",
      "\n",
      "Time to run 3th iteration:\n",
      "0.4512024521827698 minutes\n",
      "\n",
      "Time to run 4th iteration:\n",
      "0.4629654049873352 minutes\n",
      "\n",
      "Time to run 5th iteration:\n",
      "0.4725295702616374 minutes\n",
      "\n",
      "Time to run 6th iteration:\n",
      "0.4792789538701375 minutes\n",
      "\n",
      "Time to run 7th iteration:\n",
      "0.4884373307228088 minutes\n",
      "\n",
      "Time to run 8th iteration:\n",
      "0.5129196921984355 minutes\n",
      "\n",
      "Time to run 9th iteration:\n",
      "0.5100484093030294 minutes\n",
      "\n",
      "Time to run 10th iteration:\n",
      "0.5196276545524597 minutes\n",
      "\n",
      "Time to run 11th iteration:\n",
      "0.5320924043655395 minutes\n",
      "\n",
      "Time to run 12th iteration:\n",
      "0.5372490247090658 minutes\n",
      "\n",
      "Time to run 13th iteration:\n",
      "0.5370441754659017 minutes\n",
      "\n",
      "Time to run 14th iteration:\n",
      "0.5398803313573202 minutes\n",
      "\n",
      "Time to run 15th iteration:\n",
      "0.5418726603190104 minutes\n",
      "\n",
      "Time to run 16th iteration:\n",
      "0.5493841250737508 minutes\n",
      "\n",
      "Time to run 17th iteration:\n",
      "0.5475178082784017 minutes\n",
      "\n",
      "Time to run 18th iteration:\n",
      "0.5520006616910299 minutes\n",
      "\n",
      "Time to run 19th iteration:\n",
      "0.5524972240130107 minutes\n",
      "\n",
      "Time to run 20th iteration:\n",
      "0.5586029569307963 minutes\n",
      "\n",
      "Time to run 21th iteration:\n",
      "0.5500191887219746 minutes\n",
      "\n",
      "Time to run 22th iteration:\n",
      "0.5513601938883463 minutes\n",
      "\n",
      "Time to run 23th iteration:\n",
      "0.5531833688418071 minutes\n",
      "\n",
      "Time to run 24th iteration:\n",
      "0.5628758509953816 minutes\n",
      "\n",
      "Time to run 25th iteration:\n",
      "0.5593009114265441 minutes\n",
      "\n",
      "Time to run 26th iteration:\n",
      "0.5624057491620381 minutes\n",
      "\n",
      "Time to run 27th iteration:\n",
      "0.5630403757095337 minutes\n",
      "\n",
      "Time to run 28th iteration:\n",
      "0.5677914063135783 minutes\n",
      "\n",
      "Time to run 29th iteration:\n",
      "0.5680055379867553 minutes\n",
      "\n",
      "Time to run 30th iteration:\n",
      "0.5716877301534017 minutes\n",
      "\n",
      "Time to run 31th iteration:\n",
      "0.5717167933781941 minutes\n",
      "\n",
      "Time to run 32th iteration:\n",
      "0.5652397632598877 minutes\n",
      "\n",
      "Time to run 33th iteration:\n",
      "0.6125972191492717 minutes\n",
      "\n",
      "Time to run 34th iteration:\n",
      "0.6144075830777486 minutes\n",
      "\n",
      "Time to run 35th iteration:\n",
      "0.6174091339111328 minutes\n",
      "\n",
      "Time to run 36th iteration:\n",
      "0.6197873433430989 minutes\n",
      "\n",
      "Time to run 37th iteration:\n",
      "0.6196675817171733 minutes\n",
      "\n",
      "Time to run 38th iteration:\n",
      "0.6200214902559916 minutes\n",
      "\n",
      "Time to run 39th iteration:\n",
      "0.6216256419817606 minutes\n",
      "\n",
      "Time to run 40th iteration:\n",
      "0.6255272467931111 minutes\n",
      "\n",
      "Time to run 41th iteration:\n",
      "0.6274047652880351 minutes\n",
      "\n",
      "Time to run 42th iteration:\n",
      "0.6280929168065389 minutes\n",
      "\n",
      "Time to run 43th iteration:\n",
      "0.630393401781718 minutes\n",
      "\n",
      "Time to run 44th iteration:\n",
      "0.6308299819628398 minutes\n",
      "\n",
      "Time to run 45th iteration:\n",
      "0.634024198849996 minutes\n",
      "\n",
      "Time to run 46th iteration:\n",
      "0.6314784248669942 minutes\n",
      "\n",
      "Time to run 47th iteration:\n",
      "0.6334661602973938 minutes\n",
      "\n",
      "Time to run 48th iteration:\n",
      "0.6311821341514587 minutes\n",
      "\n",
      "Time to run 49th iteration:\n",
      "0.6396845181783041 minutes\n",
      "\n",
      "Time to run 50th iteration:\n",
      "0.6518797993659973 minutes\n",
      "\n",
      "Time to run 51th iteration:\n",
      "0.6575328707695007 minutes\n",
      "\n",
      "Time to run 52th iteration:\n",
      "0.665102477868398 minutes\n",
      "\n",
      "Time to run 53th iteration:\n",
      "0.6671698212623596 minutes\n",
      "\n",
      "Time to run 54th iteration:\n",
      "0.6722539265950521 minutes\n",
      "\n",
      "Time to run 55th iteration:\n",
      "0.6694348931312561 minutes\n",
      "\n",
      "Time to run 56th iteration:\n",
      "0.6718273282051086 minutes\n",
      "\n",
      "Time to run 57th iteration:\n",
      "0.7031387011210124 minutes\n",
      "\n",
      "Time to run 58th iteration:\n",
      "0.6966963211695353 minutes\n",
      "\n",
      "Time to run 59th iteration:\n",
      "0.6922826727231344 minutes\n",
      "\n",
      "Time to run 60th iteration:\n",
      "0.7042439937591553 minutes\n",
      "\n",
      "Time to run 61th iteration:\n",
      "0.6960703730583191 minutes\n",
      "\n",
      "Time to run 62th iteration:\n",
      "0.7136034886042277 minutes\n",
      "\n",
      "Time to run 63th iteration:\n",
      "0.7117911179860433 minutes\n",
      "\n",
      "Time to run 64th iteration:\n",
      "0.7165437897046407 minutes\n",
      "\n",
      "Time to run 65th iteration:\n",
      "0.7920457323392233 minutes\n",
      "\n",
      "Time to run 66th iteration:\n",
      "0.7980724732081096 minutes\n",
      "\n",
      "Time to run 67th iteration:\n",
      "0.8041198889414469 minutes\n",
      "\n",
      "Time to run 68th iteration:\n",
      "0.7913885076840719 minutes\n",
      "\n",
      "Time to run 69th iteration:\n",
      "0.8213174223899842 minutes\n",
      "\n",
      "Time to run 70th iteration:\n",
      "0.816128118832906 minutes\n",
      "\n",
      "Time to run 71th iteration:\n",
      "0.818226444721222 minutes\n",
      "\n",
      "Time to run 72th iteration:\n",
      "0.8082663536071777 minutes\n",
      "\n",
      "Time to run 73th iteration:\n",
      "0.8326690117518107 minutes\n",
      "\n",
      "Time to run 74th iteration:\n",
      "0.827835742632548 minutes\n",
      "\n",
      "Time to run 75th iteration:\n",
      "0.8338318665822347 minutes\n",
      "\n",
      "Time to run 76th iteration:\n",
      "0.8307353417078654 minutes\n",
      "\n",
      "Time to run 77th iteration:\n",
      "0.8648549358050028 minutes\n",
      "\n",
      "Time to run 78th iteration:\n",
      "0.8589790185292562 minutes\n",
      "\n",
      "Time to run 79th iteration:\n",
      "0.8640542984008789 minutes\n",
      "\n",
      "Time to run 80th iteration:\n",
      "0.8221867521603902 minutes\n",
      "\n",
      "Time to run 81th iteration:\n",
      "0.8582294066747029 minutes\n",
      "\n",
      "Time to run 82th iteration:\n",
      "0.8730731646219889 minutes\n",
      "\n",
      "Time to run 83th iteration:\n",
      "0.8754522244135539 minutes\n",
      "\n",
      "Time to run 84th iteration:\n",
      "0.8737806757291158 minutes\n",
      "\n",
      "Time to run 85th iteration:\n",
      "0.8625725189844767 minutes\n",
      "\n",
      "Time to run 86th iteration:\n",
      "0.8715675830841064 minutes\n",
      "\n",
      "Time to run 87th iteration:\n",
      "0.8687849481900533 minutes\n",
      "\n",
      "Time to run 88th iteration:\n",
      "0.8649186531702677 minutes\n",
      "\n",
      "Time to run 89th iteration:\n",
      "0.8890973011652629 minutes\n",
      "\n",
      "Time to run 90th iteration:\n",
      "0.8988350470860799 minutes\n",
      "\n",
      "Time to run 91th iteration:\n",
      "0.8922391255696615 minutes\n",
      "\n",
      "Time to run 92th iteration:\n",
      "0.8794138789176941 minutes\n",
      "\n",
      "Time to run 93th iteration:\n",
      "0.9210527499516805 minutes\n",
      "\n",
      "Time to run 94th iteration:\n",
      "0.9120907068252564 minutes\n",
      "\n",
      "Time to run 95th iteration:\n",
      "0.9224674503008524 minutes\n",
      "\n",
      "Time to run 96th iteration:\n",
      "0.8762879014015198 minutes\n",
      "\n",
      "Time to run 97th iteration:\n",
      "0.9105222304662068 minutes\n",
      "\n",
      "Time to run 98th iteration:\n",
      "0.9393916845321655 minutes\n",
      "\n",
      "Time to run 99th iteration:\n",
      "0.938297172387441 minutes\n",
      "\n",
      "Time to run 100th iteration:\n",
      "0.9333083589871725 minutes\n",
      "\n",
      "end\n",
      "\n",
      "Best no. of neurons:             100\n",
      "Probability of error (Training): 0.5745837906160455\n",
      "Accuracy (Training)            : 0.4254162093839545\n",
      "Total Time (sec):  4141.082028865814\n",
      "Total Time (min):  69.01803381443024\n"
     ]
    }
   ],
   "source": [
    "# device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# start = 5\n",
    "# neurons_test = np.arange(start, start+15, 1)\n",
    "# neurons = np.zeros(len(Ntrain))\n",
    "# prob_error = np.zeros(len(Ntrain))\n",
    "min_ind, min_acc, nNeurons,acc,acc_all = neuron_cross_validation(X_train,y_train,X_tensor_train,l_tensor_train)\n",
    "# neurons = nNeurons\n",
    "prob_error = min_acc\n",
    "# print(Ntrain,\"Samples...\")\n",
    "\n",
    "\n",
    "stop = time.time()\n",
    "print('end')\n",
    "print()\n",
    "print(\"Best no. of neurons:            \",nNeurons)\n",
    "print(\"Probability of error (Training):\",min_acc)\n",
    "print(\"Accuracy (Training)            :\",1-min_acc)\n",
    "print('Total Time (sec): ', stop - start) \n",
    "print('Total Time (min): ', (stop - start)/60) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best no. of neurons:             100\n",
      "Probability of error (Training): 0.5745837906160455\n",
      "Accuracy (Training): 0.4254162093839545\n"
     ]
    }
   ],
   "source": [
    "print(\"Best no. of neurons:            \",nNeurons)\n",
    "print(\"Probability of error (Training):\",min_acc)\n",
    "print(\"Accuracy (Training):\",1-min_acc)\n",
    "# print(acc)\n",
    "\n",
    "\n",
    "# plt.scatter(neurons_test,acc)\n",
    "# plt.show()\n",
    "\n",
    "start = 1\n",
    "trials = 100\n",
    "x_ax = np.arange(start, start+trials, 1)\n",
    "plt.plot(x_ax,acc)\n",
    "plt.title('Probability of Error vs. Neurons')\n",
    "plt.ylabel('p(Error)')\n",
    "plt.xlabel('Neurons')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of error with 100 Neurons (Test): 0.5732843644479605\n",
      "Time (min):  1.6019980510075886\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start = time.time()\n",
    "\n",
    "model = TwoLayerMLP(input_dim, nNeurons, output_dim)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "num_epochs = 100\n",
    "model = model_train(model, X_tensor_train, l_tensor_train, criterion, optimizer, num_epochs=num_epochs)\n",
    "\n",
    "#Validate/predict it and record p(error)\n",
    "# y_test_tensor = Tensor\n",
    "Z, accTest = model_predict(model,X_tensor_test,l_tensor_test)\n",
    "\n",
    "stop = time.time()\n",
    "\n",
    "print('Probability of error with', nNeurons,'Neurons (Test):',accTest)\n",
    "# print('Time: ', stop - start) \n",
    "print('Time (min): ', (stop - start)/60) \n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Test): 0.4267156355520395\n",
      "Worst Value    : 0.14285714285714285\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy (Test):',1-accTest)\n",
    "print('Worst Value    :',1/7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts Per Class:\n",
      "0     1.816086\n",
      "1     2.262071\n",
      "2     2.922130\n",
      "3     3.818975\n",
      "4    13.599542\n",
      "5    34.873576\n",
      "6    40.707620\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Counts Per Class:\")\n",
    "print(df.index.value_counts().sort_index()/N*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "start = time.time()\n",
    "\n",
    "model = TwoLayerMLP(input_dim, nNeurons, output_dim)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "num_epochs = 100\n",
    "model = model_train(model, X_tensor_train, l_tensor_train, criterion, optimizer, num_epochs=num_epochs)\n",
    "#Validate/predict it and record p(error)\n",
    "Z, accTest = model_predict(model,X_tensor_test,y_test)\n",
    "\n",
    "stop = time.time()\n",
    "\n",
    "print('Probability of error with', nNeurons,'Neurons (Test):',accTest)\n",
    "print('Time: ', stop - start) \n",
    "print('Time (min): ', (stop - start)/60) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print('Accuracy (Test):',1-accTest)\n",
    "print('Worst Value    :',1/7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
