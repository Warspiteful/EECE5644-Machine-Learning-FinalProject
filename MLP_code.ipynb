{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Labels: [0 1 2 3 4 5 6]\n",
      "Total Datapoints: 1272462\n",
      "Counts Per Class:\n",
      "0     23109\n",
      "1     28784\n",
      "2     37183\n",
      "3     48595\n",
      "4    173049\n",
      "5    443753\n",
      "6    517989\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>explicit</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.782</td>\n",
       "      <td>0.633</td>\n",
       "      <td>106471</td>\n",
       "      <td>0.2610</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.235</td>\n",
       "      <td>-16.389</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7970</td>\n",
       "      <td>167.679</td>\n",
       "      <td>0.655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.988</td>\n",
       "      <td>0.420</td>\n",
       "      <td>232933</td>\n",
       "      <td>0.0909</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7860</td>\n",
       "      <td>10</td>\n",
       "      <td>0.104</td>\n",
       "      <td>-19.388</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0409</td>\n",
       "      <td>123.089</td>\n",
       "      <td>0.227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.993</td>\n",
       "      <td>0.394</td>\n",
       "      <td>177981</td>\n",
       "      <td>0.2580</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0770</td>\n",
       "      <td>5</td>\n",
       "      <td>0.153</td>\n",
       "      <td>-9.779</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1100</td>\n",
       "      <td>74.761</td>\n",
       "      <td>0.340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.730</td>\n",
       "      <td>0.618</td>\n",
       "      <td>125300</td>\n",
       "      <td>0.2720</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.146</td>\n",
       "      <td>-18.515</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7310</td>\n",
       "      <td>67.141</td>\n",
       "      <td>0.449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.993</td>\n",
       "      <td>0.475</td>\n",
       "      <td>188600</td>\n",
       "      <td>0.4070</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0134</td>\n",
       "      <td>9</td>\n",
       "      <td>0.116</td>\n",
       "      <td>-13.011</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0492</td>\n",
       "      <td>74.130</td>\n",
       "      <td>0.594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   acousticness  danceability  duration_ms  energy  explicit  \\\n",
       "0         0.782         0.633       106471  0.2610         1   \n",
       "0         0.988         0.420       232933  0.0909         0   \n",
       "0         0.993         0.394       177981  0.2580         0   \n",
       "0         0.730         0.618       125300  0.2720         1   \n",
       "0         0.993         0.475       188600  0.4070         0   \n",
       "\n",
       "   instrumentalness  key  liveness  loudness  mode  speechiness    tempo  \\\n",
       "0            0.0000    1     0.235   -16.389     1       0.7970  167.679   \n",
       "0            0.7860   10     0.104   -19.388     1       0.0409  123.089   \n",
       "0            0.0770    5     0.153    -9.779     0       0.1100   74.761   \n",
       "0            0.0000    6     0.146   -18.515     1       0.7310   67.141   \n",
       "0            0.0134    9     0.116   -13.011     1       0.0492   74.130   \n",
       "\n",
       "   valence  \n",
       "0    0.655  \n",
       "0    0.227  \n",
       "0    0.340  \n",
       "0    0.449  \n",
       "0    0.594  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from scipy.stats import multivariate_normal # MVN not univariate\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import time\n",
    "\n",
    "np.random.seed(7)\n",
    "\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "# Load in data files\n",
    "file_path = \"data.csv\"\n",
    "df = pd.read_csv(file_path, index_col='year')\n",
    "\n",
    "file_path = \"tracks_features.csv\"\n",
    "df2 = pd.read_csv(file_path, index_col='year')\n",
    "\n",
    "# file_path = \"archive\\songs_normalize.csv\"\n",
    "# df3 = pd.read_csv(file_path, index_col='year')\n",
    "\n",
    "# Delete unwanted/unnecessary columns\n",
    "df.drop(['artists','id', 'name', 'release_date','popularity' ], axis = 1, inplace = True)\n",
    "df2.drop(['artists','id', 'name', 'release_date', 'album_id','artist_ids', 'time_signature',\\\n",
    "          'track_number', 'disc_number', 'album' ], axis = 1, inplace = True)\n",
    "\n",
    "df = pd.concat([df,df2])\n",
    "\n",
    "\n",
    "### Only look at decades from 1950s to 1010s (2020 not included)\n",
    "l_drop = np.arange(1921,1950)\n",
    "l_drop = np.append(l_drop,2020)\n",
    "drop_vals = np.array([0,1900,1908,1909,1917,1920])     #for df2\n",
    "l_drop = np.concatenate((l_drop,drop_vals))\n",
    "\n",
    "# Delete unwanted years\n",
    "df.drop(labels=l_drop, axis=0, inplace = True)\n",
    "\n",
    "enc = LabelEncoder()\n",
    "labels = df.index\n",
    "standardized_labels = np.array(labels)\n",
    "enc.fit(df.index.unique())\n",
    "\n",
    "\n",
    "\n",
    "lmao = df.index\n",
    "\n",
    "# Create labels by each individual year\n",
    "y = enc.transform(standardized_labels)\n",
    "Y = enc.transform(np.unique(standardized_labels))\n",
    "\n",
    "# Convert labels (year) to decades\n",
    "y_decade = y//10\n",
    "Y_decade = np.unique(y_decade)\n",
    "\n",
    "enc.fit(df['explicit'].unique())\n",
    "df['explicit'] = enc.transform(df['explicit'])\n",
    "\n",
    "\n",
    "df.set_index(y_decade, inplace=True)\n",
    "\n",
    "aa = df.index.value_counts().sort_index().to_numpy()\n",
    "priors = aa/len(df.index)\n",
    "check = np.sum(priors)\n",
    "class_priors = np.diag(priors)\n",
    "num_classes = len(Y_decade)\n",
    "# print(df)\n",
    "\n",
    "print()\n",
    "N = len(df)\n",
    "print('Labels:',Y_decade)\n",
    "print('Total Datapoints:',N)\n",
    "print(\"Counts Per Class:\")\n",
    "print(df.index.value_counts().sort_index())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regularized_cov(X, lambda_reg):\n",
    "    n = X.shape[0]\n",
    "    sigma = np.cov(X)\n",
    "    # Selecting the regularization parameter should be performed using CV and a separate data subset\n",
    "    # As I only went by training set performance (overfitting) in this problem, I settled on lambda=1/n\n",
    "    sigma += lambda_reg * np.eye(n)\n",
    "    return sigma\n",
    "\n",
    "# Normalize data as zero mean gaussian and compute mean and stdev\n",
    "covariance = df.std()\n",
    "mean = df.mean()\n",
    "X = (df-df.mean())/df.std()\n",
    "# print(X)\n",
    "mu = X.groupby([X.index]).mean().to_numpy()\n",
    "n = mu.shape[1]\n",
    "Sigma = np.array([regularized_cov(X[y_decade == l].T,(1/n)) for l in range(num_classes)])\n",
    "# Sigma = np.array([np.cov(X[y_decade == l].T) for l in range(num_classes)])\n",
    "# print(mu)\n",
    "# print(Sigma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Samples: 1272462.0\n",
      "Confusion matrix:\n",
      "[[  1194    453    396    457   2708   7183   5409]\n",
      " [  2227   3087   1298    734   3319   8127   5721]\n",
      " [   927   2914   7341   7837  13729  23068  20787]\n",
      " [    14     22    254    828    571    579    470]\n",
      " [   977   1029    851   2481  17242  22931  22067]\n",
      " [ 16305  19566  24178  30310 106524 284366 286614]\n",
      " [  1465   1713   2865   5948  28956  97499 176921]]\n",
      "Total Mumber of Misclassified Samples: 781483.0\n",
      "Empirically Estimated Probability of Error: 0.6142\n",
      "Accuracy: 0.38584963637421\n"
     ]
    }
   ],
   "source": [
    "### Calculate MLE\n",
    "\n",
    "C = len(priors)\n",
    "class_cond_likelihoods = np.array([multivariate_normal.pdf(X, mu[j], Sigma[j]) for j in range(C)])\n",
    "# print(np.max(class_cond_likelihoods))\n",
    "\n",
    "# Class Posterior\n",
    "# P(yj | x) = p(x | yj) * P(yj) / p(x)\n",
    "class_posteriors = class_priors.dot(class_cond_likelihoods)\n",
    "\n",
    "decisions = np.argmax(class_posteriors, axis=0)\n",
    "\n",
    "sample_class_counts = np.array([sum(y == j) for j in Y_decade])\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_mat = np.zeros((C, C))\n",
    "display_mat = np.zeros((C,C))\n",
    "for i in range(C): # Each decision option\n",
    "    for j in range(C): # Each class label\n",
    "        ind_ij = np.argwhere((decisions==Y_decade[i]) & (y_decade==Y_decade[j]))\n",
    "        display_mat[i, j] = len(ind_ij) # Average over class sample count\n",
    "        conf_mat[i, j] = len(ind_ij)/sample_class_counts[j]\n",
    "\n",
    "print(\"Total Number of Samples:\",np.sum(display_mat))\n",
    "print(\"Confusion matrix:\")\n",
    "print(display_mat.astype(int))\n",
    "# print(1950+(Y_decade*10))\n",
    "\n",
    "correct_class_samples = np.sum(np.diag(display_mat))\n",
    "print(\"Total Mumber of Misclassified Samples: {}\".format(N - correct_class_samples))\n",
    "\n",
    "prob_error = 1 - (correct_class_samples / N)\n",
    "print(\"Empirically Estimated Probability of Error: {:.4f}\".format(prob_error))\n",
    "print(\"Accuracy:\",1-prob_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time to run (sec):  0.0\n",
      "Time to run (min):  0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data into test and train data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.values, y_decade, test_size = 0.30)\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# # Random Forest Model\n",
    "# clf = RandomForestClassifier(n_estimators = 100)\n",
    "# print('done')\n",
    "\n",
    "# clf.fit(X_train, y_train)\n",
    "# print('done')\n",
    "\n",
    "# feature_imp = pd.Series(clf.feature_importances_, index = df.columns).sort_values(ascending = False)\n",
    "# print('done')\n",
    "\n",
    "# print(feature_imp)\n",
    "\n",
    "\n",
    "# y_pred = clf.predict(X_test)\n",
    " \n",
    "# # metrics are used to find accuracy or error\n",
    "# from sklearn import metrics \n",
    "# print()\n",
    " \n",
    "# # using metrics module for accuracy calculation\n",
    "# print(\"ACCURACY OF THE MODEL: \", metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "stop = time.time()\n",
    "print()\n",
    "print('Time to run (sec): ', stop - start) \n",
    "print('Time to run (min): ', (stop - start)/60) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.cuda.device at 0x1743bc55310>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# Utility to visualize PyTorch network and shapes\n",
    "from torchsummary import summary\n",
    "from sklearn.model_selection import KFold # Important new include\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "torch.manual_seed(7) \n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "torch.cuda.device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLayerMLP(nn.Module):\n",
    "    # Two-layer MLP (not really a perceptron activation function...) network class\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, C):\n",
    "        super(TwoLayerMLP, self).__init__()\n",
    "        # Fully connected layer WX + b mapping from input_dim (n) -> hidden_layer_dim\n",
    "        self.input_fc = nn.Linear(input_dim, hidden_dim)\n",
    "        # Hidden Layer\n",
    "        X = nn.Linear(hidden_dim, hidden_dim)\n",
    "\n",
    "        # Output layer again fully connected mapping from hidden_layer_dim -> outputs_dim (C)\n",
    "        self.output_fc = nn.Linear(hidden_dim, C)\n",
    "        # Log Softmax (faster and better than straight Softmax)\n",
    "        # dim=1 refers to the dimension along which the softmax operation is computed\n",
    "        # In this case computing probabilities across dim 1, i.e., along classes at output layer\n",
    "        self.log_softmax = nn.LogSoftmax(dim=1) \n",
    "        \n",
    "    # Don't call this function directly!! \n",
    "    # Simply pass input to model and forward(input) returns output, e.g. model(X)\n",
    "    def forward(self, X):\n",
    "        # X = [batch_size, input_dim (n)]\n",
    "        X = self.input_fc(X)\n",
    "        # Non-linear activation function, e.g. ReLU (default good choice)\n",
    "        # Could also choose F.softplus(x) for smooth-ReLU, empirically worse than ReLU\n",
    "        X = F.relu(X)\n",
    "        X = self.hidden_layer(X)\n",
    "        # X = [batch_size, hidden_dim]\n",
    "        \n",
    "        # Add another hidden layer\n",
    "        X = F.relu(X)\n",
    "        X = self.hidden_layer(X)\n",
    "        \n",
    "        # Connect to last layer and output 'logits'\n",
    "        X = self.output_fc(X)\n",
    "        # Squash logits to probabilities that sum up to 1\n",
    "        y = self.log_softmax(X)\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train(model, data, labels, criterion, optimizer, num_epochs=25):\n",
    "\n",
    "    # Apparently good practice to set this \"flag\" too before training\n",
    "    # Does things like make sure Dropout layers are active, gradients are updated, etc.\n",
    "    # Probably not a big deal for our toy network, but still worth developing good practice\n",
    "#     model.to(device)\n",
    "#     data = data.to(device)\n",
    "#     print(data.device)\n",
    "    \n",
    "    model.train()\n",
    "    # Optimize the neural network\n",
    "    for epoch in range(num_epochs):\n",
    "        # These outputs represent the model's predicted probabilities for each class. \n",
    "        outputs = model(data)\n",
    "        # Criterion computes the cross entropy loss between input and target\n",
    "        loss = criterion(outputs, labels)\n",
    "        # Set gradient buffers to zero explicitly before backprop\n",
    "        optimizer.zero_grad()\n",
    "        # Backward pass to compute the gradients through the network\n",
    "        loss.backward()\n",
    "        # GD step update\n",
    "        optimizer.step()\n",
    "        \n",
    "    return model\n",
    "    \n",
    "    \n",
    "def model_predict(model, data, labels):\n",
    "    # Similar idea to model.train(), set a flag to let network know your in \"inference\" mode\n",
    "#     model.to(device)\n",
    "    labels.to(device)\n",
    "\n",
    "    model.eval()\n",
    "    N = len(data)\n",
    "#     print(N)\n",
    "    # Disabling gradient calculation is useful for inference, only forward pass!!\n",
    "    with torch.no_grad():\n",
    "        # Evaluate nn on test data and compare to true labels\n",
    "        predicted_labels = model(data)\n",
    "        # Back to numpy\n",
    "        predicted_labels = predicted_labels.detach().cpu().numpy()\n",
    "        Z = np.argmax(predicted_labels, 1)\n",
    "#     print(labels)\n",
    "    conf_mat = confusion_matrix(Z, labels.cpu())\n",
    "    correct_class_samples = np.sum(np.diag(conf_mat))\n",
    "    prob_error = 1 - (correct_class_samples / N)\n",
    "#     print(conf_mat)\n",
    "#     print(\"Total Number of Misclassified Samples: {:d}\".format(N - correct_class_samples))\n",
    "#     print(\"Empirically Estimated Probability of Error: {:.4f}\".format(prob_error))\n",
    "#     print()\n",
    "    return Z, prob_error, conf_mat\n",
    "\n",
    "# Z, acc = model_predict(model,X_tensor[0],labels[0])\n",
    "# print(acc)\n",
    "\n",
    "def neuron_cross_validation(X,labels,X_tensor,l_tensor):#,Xtest,labelsTest):\n",
    "\n",
    "    K = 10   #No. of K-folds in CV\n",
    "    kf = KFold(n_splits=K, shuffle=True)\n",
    "    start = 1    # starting no. of neurons\n",
    "    trials = 100      # no. of trials\n",
    "    neurons = np.arange(start, start+trials, 1)\n",
    "    n_hidden = len(neurons)\n",
    "    \n",
    "#     X = X.to(device)\n",
    "#     labels = labels.to(device)\n",
    "\n",
    "    #Assign data to GPU\n",
    "    X_tensor = X_tensor.to(device)\n",
    "    l_tensor = l_tensor.to(device)\n",
    "    \n",
    "    # Store predictions per degree using ordered X samples for plotting best fit lines\n",
    "#     y_train_preds_ordered = np.empty(n_degs, dtype=np.ndarray)\n",
    "    # Allocate space for CV\n",
    "    # No need for training loss storage too but useful comparison\n",
    "    mse_valid_mk = np.empty((n_hidden, K)) \n",
    "    mse_train_mk = np.empty((n_hidden, K)) # Indexed by model m, data partition k\n",
    "    acc = np.empty((n_hidden, K))\n",
    "    accTest = np.empty(n_hidden)\n",
    "    i = 0\n",
    "    for n in neurons: \n",
    "        start_it = time.time()\n",
    "        k = 0\n",
    "        for train_indices, valid_indices in kf.split(X):\n",
    "            # Extract the training and validation sets from the K-fold split\n",
    "            X_train_k = X_tensor[train_indices]\n",
    "            y_train_k = l_tensor[train_indices]\n",
    "            X_train_tensor = (X_train_k)\n",
    "            y_train_tensor = (y_train_k)\n",
    "            \n",
    "            X_valid_k = X_tensor[valid_indices]\n",
    "            y_valid_k = l_tensor[valid_indices]\n",
    "            X_valid_tensor = (X_valid_k)\n",
    "            \n",
    "            \n",
    "            #Train it\n",
    "            model = TwoLayerMLP(input_dim, n, output_dim)\n",
    "            model.to(device)\n",
    "            optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            num_epochs = 100\n",
    "            model = model_train(model, X_train_tensor, y_train_tensor, criterion, optimizer, num_epochs=num_epochs)\n",
    "            \n",
    "            #Validate/predict it and record p(error)\n",
    "            Z, acc[i,k], conf_matrix = model_predict(model,X_valid_tensor,y_valid_k)\n",
    "#             Z, accTest[i,k] = model_predict(model,X_tensor_test,labelsTest)\n",
    "            k += 1\n",
    "        i+=1\n",
    "#         print(i, 'done')\n",
    "\n",
    "        stop_it = time.time()\n",
    "        t = stop_it - start_it\n",
    "#         print('Time to run {}th iteration: {}'.format(i,t)) \n",
    "        print('Time to run {}th iteration:'.format(i))\n",
    "        print('{} minutes'.format(t/60)) \n",
    "        print()\n",
    "    accuracy = np.mean(acc, axis=1)\n",
    "    min_acc = np.min(accuracy)\n",
    "    min_ind = np.argmin(accuracy)\n",
    "    n_optimal = neurons[min_ind]\n",
    "    \n",
    "    return min_ind, min_acc, n_optimal, accuracy, acc#, models, accTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "done\n",
      "train: 890723\n",
      "test:  381739\n"
     ]
    }
   ],
   "source": [
    "print(device)\n",
    "torch.cuda.device(device)\n",
    "\n",
    "# return\n",
    "input_dim = X.shape[1]\n",
    "n_hidden_neurons = 16   #VARY THIS FOR CV\n",
    "output_dim = C\n",
    "\n",
    "# Convert data to pytorch tensors\n",
    "X_tensor_train = torch.FloatTensor(X_train)\n",
    "X_tensor_test = torch.FloatTensor(X_test)\n",
    "\n",
    "\n",
    "l_tensor_train = torch.LongTensor(y_train)\n",
    "l_tensor_test = torch.LongTensor(y_test)\n",
    "\n",
    "\n",
    "print('done')\n",
    "# Convert numpy structures to PyTorch tensors, as these are the data types required by the library\n",
    "print('train:',len(X_train))\n",
    "print('test: ',len(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to run 1th iteration:\n",
      "0.4559074322382609 minutes\n",
      "\n",
      "Time to run 2th iteration:\n",
      "0.4384065667788188 minutes\n",
      "\n",
      "Time to run 3th iteration:\n",
      "0.44165541330973307 minutes\n",
      "\n",
      "Time to run 4th iteration:\n",
      "0.44390332301457724 minutes\n",
      "\n",
      "Time to run 5th iteration:\n",
      "0.445858895778656 minutes\n",
      "\n",
      "Time to run 6th iteration:\n",
      "0.45025063753128053 minutes\n",
      "\n",
      "Time to run 7th iteration:\n",
      "0.4598331054051717 minutes\n",
      "\n",
      "Time to run 8th iteration:\n",
      "0.4569467385609945 minutes\n",
      "\n",
      "Time to run 9th iteration:\n",
      "0.460508930683136 minutes\n",
      "\n",
      "Time to run 10th iteration:\n",
      "0.46407422224680583 minutes\n",
      "\n",
      "Time to run 11th iteration:\n",
      "0.4776325305302938 minutes\n",
      "\n",
      "Time to run 12th iteration:\n",
      "0.4781716108322144 minutes\n",
      "\n",
      "Time to run 13th iteration:\n",
      "0.473454745610555 minutes\n",
      "\n",
      "Time to run 14th iteration:\n",
      "0.47715186278025307 minutes\n",
      "\n",
      "Time to run 15th iteration:\n",
      "0.4786662658055623 minutes\n",
      "\n",
      "Time to run 16th iteration:\n",
      "0.4940929611523946 minutes\n",
      "\n",
      "Time to run 17th iteration:\n",
      "0.48810981909434 minutes\n",
      "\n",
      "Time to run 18th iteration:\n",
      "0.49332417249679567 minutes\n",
      "\n",
      "Time to run 19th iteration:\n",
      "0.4954228679339091 minutes\n",
      "\n",
      "Time to run 20th iteration:\n",
      "0.4997463266054789 minutes\n",
      "\n",
      "Time to run 21th iteration:\n",
      "0.5008298675219218 minutes\n",
      "\n",
      "Time to run 22th iteration:\n",
      "0.5133051037788391 minutes\n",
      "\n",
      "Time to run 23th iteration:\n",
      "0.5134017030398051 minutes\n",
      "\n",
      "Time to run 24th iteration:\n",
      "0.5203917741775512 minutes\n",
      "\n",
      "Time to run 25th iteration:\n",
      "0.513035257657369 minutes\n",
      "\n",
      "Time to run 26th iteration:\n",
      "0.5162579695383708 minutes\n",
      "\n",
      "Time to run 27th iteration:\n",
      "0.5333072463671367 minutes\n",
      "\n",
      "Time to run 28th iteration:\n",
      "0.5245063424110412 minutes\n",
      "\n",
      "Time to run 29th iteration:\n",
      "0.5227753281593323 minutes\n",
      "\n",
      "Time to run 30th iteration:\n",
      "0.5253885666529338 minutes\n",
      "\n",
      "Time to run 31th iteration:\n",
      "0.5337796807289124 minutes\n",
      "\n",
      "Time to run 32th iteration:\n",
      "0.5443348964055379 minutes\n",
      "\n",
      "Time to run 33th iteration:\n",
      "0.5841126362482707 minutes\n",
      "\n",
      "Time to run 34th iteration:\n",
      "0.5817903200785319 minutes\n",
      "\n",
      "Time to run 35th iteration:\n",
      "0.5765454093615214 minutes\n",
      "\n",
      "Time to run 36th iteration:\n",
      "0.5830479701360066 minutes\n",
      "\n",
      "Time to run 37th iteration:\n",
      "0.5869710842768351 minutes\n",
      "\n",
      "Time to run 38th iteration:\n",
      "0.5894609808921814 minutes\n",
      "\n",
      "Time to run 39th iteration:\n",
      "0.5913281043370565 minutes\n",
      "\n",
      "Time to run 40th iteration:\n",
      "0.5973265051841736 minutes\n",
      "\n",
      "Time to run 41th iteration:\n",
      "0.6063454071680705 minutes\n",
      "\n",
      "Time to run 42th iteration:\n",
      "0.5925833106040954 minutes\n",
      "\n",
      "Time to run 43th iteration:\n",
      "0.6028011322021485 minutes\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-ea40732b3506>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# CV for best number of neurons\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mmin_ind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnNeurons\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0macc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0macc_all\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mneuron_cross_validation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_tensor_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ml_tensor_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;31m# neurons = nNeurons\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mprob_error\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin_acc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-209c3b90a654>\u001b[0m in \u001b[0;36mneuron_cross_validation\u001b[1;34m(X, labels, X_tensor, l_tensor)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m             \u001b[1;31m#Validate/predict it and record p(error)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m             \u001b[0mZ\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_valid_tensor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_valid_k\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    105\u001b[0m \u001b[1;31m#             Z, accTest[i,k] = model_predict(model,X_tensor_test,labelsTest)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m             \u001b[0mk\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-209c3b90a654>\u001b[0m in \u001b[0;36mmodel_predict\u001b[1;34m(model, data, labels)\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0mpredicted_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[1;31m# Back to numpy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m         \u001b[0mpredicted_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredicted_labels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m         \u001b[0mZ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredicted_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;31m#     print(labels)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Keep track of time to check performance and runtime\n",
    "start = time.time()\n",
    "\n",
    "# start = 5\n",
    "# neurons_test = np.arange(start, start+15, 1)\n",
    "# neurons = np.zeros(len(Ntrain))\n",
    "# prob_error = np.zeros(len(Ntrain))\n",
    "\n",
    "# CV for best number of neurons\n",
    "min_ind, min_acc, nNeurons,acc,acc_all = neuron_cross_validation(X_train,y_train,X_tensor_train,l_tensor_train)\n",
    "# neurons = nNeurons\n",
    "prob_error = min_acc\n",
    "# print(Ntrain,\"Samples...\")\n",
    "\n",
    "\n",
    "stop = time.time()\n",
    "print('end')\n",
    "print('Total Time (sec): ', stop - start) \n",
    "print('Total Time (min): ', (stop - start)/60)\n",
    "print()\n",
    "print(\"Best no. of neurons:            \",nNeurons)\n",
    "print(\"Probability of error (Training):\",min_acc)\n",
    "print(\"Accuracy (Training)            :\",1-min_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best no. of neurons:            \",nNeurons)\n",
    "print(\"Probability of error (Training):\",min_acc)\n",
    "print(\"Accuracy (Training):\",1-min_acc)\n",
    "# print(acc)\n",
    "\n",
    "\n",
    "# plt.scatter(neurons_test,acc)\n",
    "# plt.show()\n",
    "\n",
    "#Plot performance vs neuron count\n",
    "start = 1\n",
    "trials = 150\n",
    "x_ax = np.arange(start, start+trials, 1)\n",
    "plt.plot(x_ax,acc)\n",
    "plt.title('Probability of Error vs. Neurons')\n",
    "plt.ylabel('p(Error)')\n",
    "plt.xlabel('Neurons')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Optimal number of neurons on test data\n",
    "start = time.time()\n",
    "\n",
    "model = TwoLayerMLP(input_dim, nNeurons, output_dim)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "num_epochs = 100\n",
    "model = model_train(model, X_tensor_train, l_tensor_train, criterion, optimizer, num_epochs=num_epochs)\n",
    "\n",
    "#Validate/predict it and record p(error)\n",
    "# y_test_tensor = Tensor\n",
    "Z, accTest, conf_matrix = model_predict(model,X_tensor_test,l_tensor_test)\n",
    "\n",
    "stop = time.time()\n",
    "\n",
    "print('Probability of error with', nNeurons,'Neurons (Test):',accTest)\n",
    "# print('Time: ', stop - start) \n",
    "print('Time (min): ', (stop - start)/60) \n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Accuracy (Test):',1-accTest)\n",
    "print('Worst Value    :',1/7)\n",
    "print(\"Percent Per Class:\")\n",
    "print(df.index.value_counts().sort_index()/N*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Report Recall and Precision\n",
    "#Precision and recall of model\n",
    "print(conf_matrix)\n",
    "for i in range(len(conf_matrix)):\n",
    "    recall = np.mean(conf_matrix, axis = 0)\n",
    "    precision = np.mean(conf_matrix, axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "start = time.time()\n",
    "\n",
    "model = TwoLayerMLP(input_dim, nNeurons, output_dim)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "num_epochs = 100\n",
    "model = model_train(model, X_tensor_train, l_tensor_train, criterion, optimizer, num_epochs=num_epochs)\n",
    "#Validate/predict it and record p(error)\n",
    "Z, accTest = model_predict(model,X_tensor_test,y_test)\n",
    "\n",
    "stop = time.time()\n",
    "\n",
    "print('Probability of error with', nNeurons,'Neurons (Test):',accTest)\n",
    "print('Time: ', stop - start) \n",
    "print('Time (min): ', (stop - start)/60) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print('Accuracy (Test):',1-accTest)\n",
    "print('Worst Value    :',1/7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
