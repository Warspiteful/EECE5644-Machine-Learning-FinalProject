{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 6 6 6]\n",
      "[19950 20000 20000 20000 20000 20000 19900]\n",
      "5    20000\n",
      "4    20000\n",
      "3    20000\n",
      "2    20000\n",
      "1    20000\n",
      "0    19950\n",
      "6    19900\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from scipy.stats import multivariate_normal # MVN not univariate\n",
    "\n",
    "file_path = \"data.csv\"\n",
    "df = pd.read_csv(file_path, index_col='year')\n",
    "\n",
    "df.drop(['artists','id', 'name', 'release_date' ], axis = 1, inplace = True)\n",
    "\n",
    "### Only look at decades from 50s to 10s (2020 not included)\n",
    "l_drop = np.arange(1921,1950)\n",
    "l_drop = np.append(l_drop,2020)\n",
    "df.drop(labels=l_drop, axis=0, inplace = True)\n",
    "\n",
    "enc = LabelEncoder()\n",
    "labels = df.index\n",
    "standardized_labels = np.array(labels)\n",
    "enc.fit(df.index.unique())\n",
    "\n",
    "\n",
    "\n",
    "lmao = df.index\n",
    "y = enc.transform(standardized_labels)\n",
    "Y = enc.transform(np.unique(standardized_labels))\n",
    "\n",
    "y_decade = y//10\n",
    "Y_decade = np.unique(y_decade)\n",
    "\n",
    "enc.fit(df['explicit'].unique())\n",
    "df['explicit'] = enc.transform(df['explicit'])\n",
    "\n",
    "df.set_index(y_decade, inplace=True)\n",
    "aa = df.index.value_counts().sort_index().to_numpy()\n",
    "priors = aa/len(df.index)\n",
    "check = np.sum(priors)\n",
    "class_priors = np.diag(priors)\n",
    "num_classes = len(Y_decade)\n",
    "print(y_decade)\n",
    "print(aa)\n",
    "print(df.index.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for l in range(num_classes):\n",
    "#     print(X[y_decade == l])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8.40149803e-01  4.77069233e-01  2.20807673e+05  2.87032280e-01\n",
      "   8.62155388e-03  2.43156158e-01  5.03062657e+00  2.09645654e-01\n",
      "  -1.47921127e+01  7.13233083e-01  9.94706767e+00  9.68375739e-02\n",
      "   1.10601903e+02  4.76690994e-01]\n",
      " [ 6.21165633e-01  4.96651230e-01  2.10132680e+05  4.15795562e-01\n",
      "   6.00000000e-04  1.54654999e-01  5.10565000e+00  2.09356285e-01\n",
      "  -1.27372676e+01  7.54150000e-01  2.56291500e+01  5.88183550e-02\n",
      "   1.15473647e+02  5.56917659e-01]\n",
      " [ 3.92205985e-01  5.26920000e-01  2.54870402e+05  5.38543794e-01\n",
      "   3.20000000e-03  1.13695970e-01  5.11465000e+00  2.20958510e-01\n",
      "  -1.13881736e+01  7.42850000e-01  3.50491000e+01  6.06646750e-02\n",
      "   1.20126717e+02  5.87902195e-01]\n",
      " [ 2.86104236e-01  5.49658215e-01  2.52207315e+05  6.02474928e-01\n",
      "   2.43500000e-02  1.18441519e-01  5.29995000e+00  2.05266970e-01\n",
      "  -1.11292057e+01  7.11450000e-01  3.70011500e+01  6.29248650e-02\n",
      "   1.21488896e+02  5.70081416e-01]\n",
      " [ 2.92137031e-01  5.71789510e-01  2.49228373e+05  5.94564894e-01\n",
      "   1.18650000e-01  1.02185259e-01  5.33540000e+00  1.99207590e-01\n",
      "  -9.85196880e+00  7.20050000e-01  4.36275000e+01  8.27396800e-02\n",
      "   1.19333221e+02  5.49937195e-01]\n",
      " [ 2.58533735e-01  5.76233880e-01  2.40572645e+05  6.58571087e-01\n",
      "   1.42700000e-01  7.75975419e-02  5.28905000e+00  1.95839574e-01\n",
      "  -7.36505510e+00  6.88350000e-01  4.94086500e+01  8.76970550e-02\n",
      "   1.21360571e+02  5.33421382e-01]\n",
      " [ 2.56206983e-01  5.99045487e-01  2.24639606e+05  6.32783670e-01\n",
      "   2.85979899e-01  7.08216717e-02  5.19819095e+00  1.89186508e-01\n",
      "  -7.38303623e+00  6.50552764e-01  5.95628141e+01  1.00971864e-01\n",
      "   1.20784860e+02  4.61508462e-01]]\n",
      "[[[ 3.52188890e-01 -1.33329936e-01  1.69767160e-02 ... -1.15372927e-01\n",
      "   -7.90126767e-02 -1.65505922e-01]\n",
      "  [-1.33329936e-01  9.92305747e-01 -2.21322430e-01 ...  4.66816729e-01\n",
      "    1.09051787e-01  6.30580149e-01]\n",
      "  [ 1.69767160e-02 -2.21322430e-01  1.74025671e+00 ... -5.81311863e-02\n",
      "   -5.51502712e-02 -2.94675615e-01]\n",
      "  ...\n",
      "  [-1.15372927e-01  4.66816729e-01 -5.81311863e-02 ...  2.57290085e+00\n",
      "    6.29635977e-03  1.12782475e-01]\n",
      "  [-7.90126767e-02  1.09051787e-01 -5.51502712e-02 ...  6.29635977e-03\n",
      "    1.13014764e+00  3.07993545e-01]\n",
      "  [-1.65505922e-01  6.30580149e-01 -2.94675615e-01 ...  1.12782475e-01\n",
      "    3.07993545e-01  1.16646954e+00]]\n",
      "\n",
      " [[ 7.42715079e-01 -1.21802302e-01  3.21265895e-02 ...  2.71321484e-02\n",
      "   -1.27507840e-01 -2.81437488e-01]\n",
      "  [-1.21802302e-01  8.62502247e-01 -1.90392950e-01 ...  6.69549858e-02\n",
      "   -7.80000107e-03  5.27173583e-01]\n",
      "  [ 3.21265895e-02 -1.90392950e-01  1.32670451e+00 ...  3.44481960e-02\n",
      "   -4.65739843e-02 -3.10004339e-01]\n",
      "  ...\n",
      "  [ 2.71321484e-02  6.69549858e-02  3.44481960e-02 ...  7.27662848e-01\n",
      "    1.43306306e-02  3.48911997e-02]\n",
      "  [-1.27507840e-01 -7.80000107e-03 -4.65739843e-02 ...  1.43306306e-02\n",
      "    1.02557771e+00  2.14704968e-01]\n",
      "  [-2.81437488e-01  5.27173583e-01 -3.10004339e-01 ...  3.48911997e-02\n",
      "    2.14704968e-01  1.05244639e+00]]\n",
      "\n",
      " [[ 8.13828749e-01 -6.12535952e-02 -1.05665217e-01 ... -1.33609107e-03\n",
      "   -1.39631269e-01 -2.41863136e-01]\n",
      "  [-6.12535952e-02  8.64745579e-01 -1.57637917e-01 ...  4.36259209e-02\n",
      "   -1.30208628e-01  4.91672190e-01]\n",
      "  [-1.05665217e-01 -1.57637917e-01  1.35271460e+00 ... -5.81696840e-03\n",
      "   -2.46115562e-02 -1.93128440e-01]\n",
      "  ...\n",
      "  [-1.33609107e-03  4.36259209e-02 -5.81696840e-03 ...  5.28062239e-01\n",
      "    2.94217014e-02  1.36716117e-02]\n",
      "  [-1.39631269e-01 -1.30208628e-01 -2.46115562e-02 ...  2.94217014e-02\n",
      "    9.63031481e-01  1.09368865e-01]\n",
      "  [-2.41863136e-01  4.91672190e-01 -1.93128440e-01 ...  1.36716117e-02\n",
      "    1.09368865e-01  9.87131062e-01]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 8.27214829e-01 -1.73460412e-01 -6.84007302e-02 ... -1.08180477e-01\n",
      "   -8.52762417e-02 -1.67160154e-01]\n",
      "  [-1.73460412e-01  1.14168135e+00 -6.30277937e-02 ...  2.49046041e-01\n",
      "   -1.71979953e-01  5.74495480e-01]\n",
      "  [-6.84007302e-02 -6.30277937e-02  7.02656096e-01 ... -1.96997346e-02\n",
      "   -4.18021243e-02 -1.74627062e-01]\n",
      "  ...\n",
      "  [-1.08180477e-01  2.49046041e-01 -1.96997346e-02 ...  9.25392124e-01\n",
      "   -8.83454452e-03  7.82531815e-02]\n",
      "  [-8.52762417e-02 -1.71979953e-01 -4.18021243e-02 ... -8.83454452e-03\n",
      "    1.10707085e+00  1.17458503e-01]\n",
      "  [-1.67160154e-01  5.74495480e-01 -1.74627062e-01 ...  7.82531815e-02\n",
      "    1.17458503e-01  1.05905449e+00]]\n",
      "\n",
      " [[ 7.69934023e-01 -1.36564153e-01 -1.18468848e-02 ... -9.92564150e-02\n",
      "   -1.26135552e-01 -1.57125554e-01]\n",
      "  [-1.36564153e-01  1.08923308e+00 -8.68817887e-02 ...  1.71004890e-01\n",
      "   -1.83961040e-01  5.71950828e-01]\n",
      "  [-1.18468848e-02 -8.68817887e-02  7.53809484e-01 ...  1.20416119e-02\n",
      "   -3.45830330e-02 -1.60034545e-01]\n",
      "  ...\n",
      "  [-9.92564150e-02  1.71004890e-01  1.20416119e-02 ...  9.13890322e-01\n",
      "   -9.31614300e-03  1.04906986e-01]\n",
      "  [-1.26135552e-01 -1.83961040e-01 -3.45830330e-02 ... -9.31614300e-03\n",
      "    1.12028929e+00  5.45853464e-02]\n",
      "  [-1.57125554e-01  5.71950828e-01 -1.60034545e-01 ...  1.04906986e-01\n",
      "    5.45853464e-02  1.01961818e+00]]\n",
      "\n",
      " [[ 7.39378700e-01 -1.50227391e-01 -1.92570392e-02 ... -5.87404805e-02\n",
      "   -1.38659609e-01 -1.46597679e-01]\n",
      "  [-1.50227391e-01  1.02708670e+00 -1.18582638e-01 ...  2.15065905e-01\n",
      "    9.91636037e-04  4.01603976e-01]\n",
      "  [-1.92570392e-02 -1.18582638e-01  6.58557726e-01 ... -3.16061694e-02\n",
      "   -1.51837304e-02 -1.05402168e-01]\n",
      "  ...\n",
      "  [-5.87404805e-02  2.15065905e-01 -3.16061694e-02 ...  1.10128092e+00\n",
      "    7.16947423e-02  4.59801853e-02]\n",
      "  [-1.38659609e-01  9.91636037e-04 -1.51837304e-02 ...  7.16947423e-02\n",
      "    1.09148778e+00  9.35317023e-02]\n",
      "  [-1.46597679e-01  4.01603976e-01 -1.05402168e-01 ...  4.59801853e-02\n",
      "    9.35317023e-02  9.18785097e-01]]]\n"
     ]
    }
   ],
   "source": [
    "def regularized_cov(X, lambda_reg):\n",
    "    n = X.shape[0]\n",
    "    sigma = np.cov(X)\n",
    "    # Selecting the regularization parameter should be performed using CV and a separate data subset\n",
    "    # As I only went by training set performance (overfitting) in this problem, I settled on lambda=1/n\n",
    "    sigma += lambda_reg * np.eye(n)\n",
    "    return sigma\n",
    "\n",
    "covariance = df.std()\n",
    "mean = df.mean()\n",
    "X = (df-df.mean())/df.std()\n",
    "\n",
    "mu = df.groupby([df.index]).mean().to_numpy()\n",
    "n = mu.shape[1]\n",
    "Sigma = np.array([regularized_cov(X[y_decade == l].T,(1/n)) for l in range(num_classes)])\n",
    "# Sigma = np.array([np.cov(X[y_decade == l].T) for l in range(num_classes)])\n",
    "print(mu)\n",
    "print(Sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = len(priors)\n",
    "\n",
    "class_cond_likelihoods = np.array([multivariate_normal.pdf(X, mu[j], Sigma[j]) for j in range(C)])\n",
    "\n",
    "# Class Posterior\n",
    "# P(yj | x) = p(x | yj) * P(yj) / p(x)\n",
    "class_posteriors = class_priors.dot(class_cond_likelihoods)\n",
    "print(np.max(class_cond_likelihoods))\n",
    "\n",
    "decisions = np.argmax(class_posteriors, axis=0)\n",
    "\n",
    "sample_class_counts = np.array([sum(y == j) for j in Y_decade])\n",
    "\n",
    "\n",
    "conf_mat = np.zeros((C, C))\n",
    "display_mat = np.zeros((C,C))\n",
    "for i in range(C): # Each decision option\n",
    "    for j in range(C): # Each class label\n",
    "        ind_ij = np.argwhere((decisions==Y_decade[i]) & (y_decade==Y_decade[j]))\n",
    "        display_mat[i, j] = len(ind_ij) # Average over class sample count\n",
    "        conf_mat[i, j] = len(ind_ij)/sample_class_counts[j]\n",
    "\n",
    "print(\"Confusion matrix:\")\n",
    "print(display_mat.astype(int))\n",
    "print(np.sum(display_mat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = df.groupby(['year']).mean().to_numpy() \n",
    "print(means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# covariance = df.std()\n",
    "# means = df.mean()\n",
    "\n",
    "\n",
    "\n",
    "# X = (df-df.mean())/df.std()\n",
    "# # print(X)\n",
    "# indexer = df.index.values\n",
    "# # print(df.head())\n",
    "\n",
    "\n",
    "\n",
    "# columns = df.columns\n",
    "\n",
    "# mu = []\n",
    "\n",
    "# labels = set()\n",
    "# for ax in df.index:\n",
    "#     labels.add(ax)\n",
    "# # print(labels)\n",
    "\n",
    "\n",
    "    \n",
    "# for index in indexer:\n",
    "#     mu.append([np.mean(X[feature][index]) for feature in df])\n",
    "# mu = np.array(mu)\n",
    "# n = mu.shape[1]\n",
    "# Sigma = []\n",
    "# # print(mu)\n",
    "# for index in indexer:\n",
    "#     Sigma.append(np.cov([X[feature][index] for feature in df]))\n",
    "# print(df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
